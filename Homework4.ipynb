{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RugiTu-13/Python-N.D./blob/main/Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbuDJ9YfLr9"
      },
      "source": [
        "Python for Data Analysis, GMC, Vilnius University, 2025\n",
        "\n",
        "# HW4: Training a succesfull machine learning (ML) model\n",
        "\n",
        "- **Tasks in this homework are built around a single data file** which should be downloaded in the Notebook as asked in the cell after the imports.\n",
        "- Packages allowed to be imported (but not necessarily needed): `scikit-learn`, `numpy`, `pandas`, `matplotlib`, `seaborn`, `tqdm`, `itertools`, `math`, `string`. Do not import any other packages.\n",
        "- **You will need to upload your solutions into your Github repository** dedicated for the Python for Data Analysis course. Use the same repository used for Homework 3.\n",
        "- Same requirements as for Homework 3:\n",
        "   - Do not write docstrings (function description comments).\n",
        "   - Keep prints informative.\n",
        "   - Do not create classes.\n",
        "   - Do not change assert statements.\n",
        "\n",
        "There are 5 tasks in this Notebook. They have slightly different numbers of points between them, with subpoints shown for each subtask e.g. (0.2p). You need to collect 8 points in total to get the maximum grade.\n",
        "\n",
        "As previously, each task consists of a text cell with task description, a code cell to solve the task, and a code cell with `assert` statements to check your code for *some* possible errors.\n",
        "\n",
        "Don't hesitate to contact me or Martynas if you are stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbIq-GLMmFHT"
      },
      "outputs": [],
      "source": [
        "# your imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import AffinityPropagation, SpectralClustering, KMeans, DBSCAN\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMmLobkRc7Eg"
      },
      "outputs": [],
      "source": [
        "# download the file using the link provided, by any method you like/understand the most,\n",
        "# but the downloading process should happen inside the Notebook.\n",
        "file_url = \"https://github.com/Tallivm/vu-python/blob/main/hw4_2025.csv\"\n",
        "raw_url = file_url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
        "data_filename = \"hw4_2025.csv\"\n",
        "\n",
        "try:\n",
        "  urllib.request.urlretrieve(raw_url, data_filename)\n",
        "  print(f\"File downloaded and saved as '{data_filename}'.\")\n",
        "except Exception as e:\n",
        " print(f\"Could not download the data file automatically: {e}\")\n",
        " print(\"If needed, download it manually and save as 'hw4_2025.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb2_t1bcmGLS"
      },
      "outputs": [],
      "source": [
        "# Run this cell to store the name of the column to predict.\n",
        "# Use this variable when needed.\n",
        "TO_PREDICT = 'snail_genus'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-MilLshM9i"
      },
      "source": [
        "# ðŸ‚ Task 1 (1 point): The new challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iebEKf1zgG86"
      },
      "source": [
        "Some researchers who collected data for SNAILAB complained that measuring a single sample takes a lot of time and is quite difficult. Many snails are actually found on fallen leaves, not on whole plants, making several measurements impossible to make. Moreover, if a snail hides inside its shell, for certain measurements the researcher is forced to wait until the snail fully appears again.\n",
        "\n",
        "An intern from SNAILAB suggested that they could use AI to solve this issue. After several discussions, they decided to train a model which would **predict the genus of a snail** from only easy-to-measure features. The intern prepared some useful data but then got sick. So, SNAILAB asks for your help once more.\n",
        "\n",
        "You will need to train several simple models to predict snail genus for a provided data set, and select the best model.\n",
        "\n",
        "But first - the provided **data should be explored**!\n",
        "\n",
        "1. (0.2p) Load the data as a DataFrame, name it `raw`. Make sure the \"Unnamed: 0\" column is not formed by providing correct parameters into the `read_csv()` function. Print out a short report (in any format you like, make it a function) using f-strings and containing this information:\n",
        "   - Number of NaN values in total, and if there are NaNs, then in which columns and how many;\n",
        "   - Min, mean, and max values of each numeric column;\n",
        "   - Unique values and their counts of each categorical column.\n",
        "\n",
        "2. (0.4p) According to the report, make certain changes to the data and name the result `clean`:\n",
        "   - If there are NaNs, remove full rows with them;\n",
        "   - Remove full rows containing seemingly incorrect measurement values (e.g. negative values for length measurements).\n",
        "   - Even if these steps were not required for this data, do it nevertheless, in a way that could be applicable to any dataset with such requirements (but maybe different columns and values).\n",
        "\n",
        "3. (0.1p) Print out the report again using the previously written function.\n",
        "\n",
        "4. (0.3p) Obtain and visualize a Spearman correlation matrix (as a heatmap) for all numeric columns. Make sure colormap is used correctly (divergent, zero in the middle), and the plot contains column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhMB6yWmjsYc"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "def print_df_report(df, name=\"Data\"):\n",
        "  print(f\"===== Report for {name} =====\")\n",
        "  total_nans = df.isna().sum().sum()\n",
        "  print(f\"Total NaN values: {total_nans}\")\n",
        "  if total_nans > 0:\n",
        "    print(\"NaNs per column:\")\n",
        "    for col, cnt in df.isna().sum().items():\n",
        "      if cnt > 0:\n",
        "        print(f\"  {col}: {cnt}\")\n",
        "  else:\n",
        "    print(\"No missing values detected.\")\n",
        "  print()\n",
        "\n",
        "  numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "  if len(numeric_cols) > 0:\n",
        "    print(\"Numeric columns (min / mean / max):\")\n",
        "    desc = df[numeric_cols].agg([\"min\", \"mean\", \"max\"])\n",
        "    for col in numeric_cols:\n",
        "      mn = desc.loc[\"min\", col]\n",
        "      mean = desc.loc[\"mean\", col]\n",
        "      mx = desc.loc[\"max\", col]\n",
        "      print(f\"  {col}: min={mn:.2f}, mean={mean:.2f}, max={mx:.2f}\")\n",
        "  else:\n",
        "    print(\"No numeric columns found.\")\n",
        "  print()\n",
        "\n",
        "  cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "  if len(cat_cols) > 0:\n",
        "    print(\"Categorical columns (value counts):\")\n",
        "    for col in cat_cols:\n",
        "      print(f\"  {col}:\")\n",
        "      vc = df[col].value_counts(dropna=True)\n",
        "      for val, cnt in vc.items():\n",
        "        print(f\"    {val!r}: {cnt}\")\n",
        "  else:\n",
        "    print(\"No categorical columns found.\")\n",
        "  print(\"==============================\\n\")\n",
        "\n",
        "\n",
        "# 1 raw data\n",
        "raw = pd.read_csv(data_filename)\n",
        "raw = raw.loc[:, ~raw.columns.str.contains(\"^Unnamed\")]\n",
        "print_df_report(raw, name=\"raw data\")\n",
        "\n",
        "# 2\n",
        "clean = raw.dropna().copy()\n",
        "\n",
        "numeric_cols = clean.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 0:\n",
        "  mask_non_negative = (clean[numeric_cols] >= 0).all(axis=1)\n",
        "  removed_rows = len(clean) - mask_non_negative.sum()\n",
        "  if removed_rows > 0:\n",
        "    print(f\"Removing {removed_rows} rows with negative numeric measurements.\")\n",
        "  clean = clean.loc[mask_non_negative].copy()\n",
        "\n",
        "# 3\n",
        "print_df_report(clean, name=\"clean data\")\n",
        "\n",
        "# 4 Spearman correlation heatmap\n",
        "numeric_cols = clean.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 1:\n",
        "  corr = clean[numeric_cols].corr(method=\"spearman\")\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(\n",
        "    corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"coolwarm\",\n",
        "    center=0,\n",
        "    xticklabels=corr.columns,\n",
        "    yticklabels=corr.columns,\n",
        "  )\n",
        "  plt.title(\"Spearman correlation of numeric features\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "else:\n",
        "  print(\"Not enough numeric columns for a correlation heatmap.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mamd7x8Be47r"
      },
      "outputs": [],
      "source": [
        "assert isinstance(raw, pd.DataFrame)\n",
        "assert isinstance(clean, pd.DataFrame)\n",
        "assert clean.isna().sum().sum() == 0\n",
        "assert len(raw.columns) == len(clean.columns)\n",
        "assert TO_PREDICT in raw.columns\n",
        "assert TO_PREDICT in clean.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFK3aoGrhOTc"
      },
      "source": [
        "# ðŸ”¨ Task 2 (1 point): Data transformation and preparation for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyc7OWgFhW6e"
      },
      "source": [
        "Next step is to prepare data for the model training. The DataFrame created during this task should be called `transformed`.\n",
        "\n",
        "1. (0.4p) Standardize numeric columns:\n",
        "   - using the `scikit-learn` package;\n",
        "   - using just `numpy`;\n",
        "   - Compare results and show that they are the same or similar enough. If there is any difference, notice how big it is.\n",
        "2. (0.3p) Encode all categorical columns except snail genus using one-hot encoding from `pandas` or `scikit-learn`. Make sure that in the end, there are N-1 columns for a categorical column with N unique values. Make sure that old categorical columns are not left in the data.\n",
        "3. (0.2p) Encode the snail genus as integer column using `pandas` or `numpy`. Make sure to create a dictionary `snail_classes` mapping snail genera and integers.\n",
        "4. (0.1p) Create `X` and `y` from the whole data. The `X` should contain all columns except the snail genus column, and the `y` should contain only the snail genus column and be a `Series` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrNa5BIHj4TO"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "# 1 Numeric columns standartization\n",
        "numeric_cols = clean.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_sklearn = scaler.fit_transform(clean[numeric_cols])\n",
        "\n",
        "means = clean[numeric_cols].mean()\n",
        "stds = clean[numeric_cols].std(ddof=0)  # population std, kaip ir StandardScaler\n",
        "scaled_numpy = (clean[numeric_cols] - means) / stds\n",
        "\n",
        "max_diff = np.abs(scaled_sklearn - scaled_numpy.values).max()\n",
        "print(f\"Maximum absolute difference between sklearn and numpy standardization: {max_diff:.6f}\")\n",
        "\n",
        "numeric_scaled_df = pd.DataFrame(\n",
        "  scaled_sklearn,\n",
        "  columns=numeric_cols,\n",
        "  index=clean.index,\n",
        ")\n",
        "\n",
        "# 2 One-hot encoding\n",
        "cat_cols = clean.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "cat_cols_to_encode = [c for c in cat_cols if c != TO_PREDICT]\n",
        "\n",
        "other_part = clean.drop(columns=numeric_cols)\n",
        "\n",
        "if len(cat_cols_to_encode) > 0:\n",
        "  transformed = pd.concat([numeric_scaled_df, other_part], axis=1)\n",
        "  transformed = pd.get_dummies(\n",
        "    transformed,\n",
        "    columns=cat_cols_to_encode,\n",
        "    drop_first=True,\n",
        "  )\n",
        "else:\n",
        "  transformed = pd.concat([numeric_scaled_df, other_part], axis=1)\n",
        "\n",
        "# 3\n",
        "snail_classes = {}\n",
        "if TO_PREDICT in transformed.columns:\n",
        "  unique_classes = sorted(transformed[TO_PREDICT].unique())\n",
        "  snail_classes = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "  transformed[TO_PREDICT] = transformed[TO_PREDICT].map(snail_classes).astype(int)\n",
        "else:\n",
        "  raise ValueError(f\"Target column {TO_PREDICT!r} not found in transformed data.\")\n",
        "\n",
        "# 4\n",
        "X = transformed.drop(columns=[TO_PREDICT]).copy()\n",
        "y = transformed[TO_PREDICT].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-yDuzSij4L7"
      },
      "outputs": [],
      "source": [
        "assert isinstance(transformed, pd.DataFrame)\n",
        "assert transformed.isna().sum().sum() == 0\n",
        "assert len(transformed.columns) > len(clean.columns)\n",
        "assert TO_PREDICT in transformed.columns\n",
        "assert transformed[TO_PREDICT].dtype == int\n",
        "assert str not in transformed.dtypes  # CHECK IF WORKS\n",
        "assert 2 in transformed[TO_PREDICT]\n",
        "assert isinstance(X, pd.DataFrame)\n",
        "assert len(X.columns) == len(transformed.columns) - 1\n",
        "assert isinstance(y, pd.Series)\n",
        "assert isinstance(snail_classes, dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy4IVj2yhXai"
      },
      "source": [
        "# ðŸŽ“ Task 3 (1 point): Model training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWgPK0cxhh68"
      },
      "source": [
        "Write a function named `split_and_train_model` which uses the standard model training pipeline:\n",
        "- It should take `X`, `y`, `random_seed`, and a function (type `Callable`) to create the model. It should also take an optional `max_iter` parameter with default value of 300.\n",
        "- Inside, it should:\n",
        "   - Correctly split `X` and `y` into `X_train`, `y_train`, `X_test`, `y_test`. You can use different names but the structure should remain the same. Use test size of 20%. Use `random_seed` to fix the random state of data splitting.\n",
        "   - Create an instance of the chosen model (by calling the provided function), with its random seed fixed to `random_seed` parameter.\n",
        "   - Use the model to fit `X_train` and `y_train`.\n",
        "   - Use the fitted model to generate predictions from `X_test`.\n",
        "   - Calculate the accuracy score by comparing `y_test` and obtained predictions. Print out the score (formatted using f-string).\n",
        "   - Return the trained model.\n",
        "   - In case of **any** exception, do not raise it, but print out the error message and return `None` instead.\n",
        "\n",
        "As an usage example, use this function with the data prepared in Task 2 and `LogisticRegression` from `scikit-learn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1Kabl8WhUt4"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "\n",
        "def split_and_train_model(X, y, random_seed, model_function, max_iter=300):\n",
        "  try:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X,\n",
        "      y,\n",
        "      test_size=0.2,\n",
        "      random_state=random_seed,\n",
        "      stratify=y,\n",
        "    )\n",
        "    model = model_function(random_state=random_seed, max_iter=max_iter)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy score: {acc:.4f}\")\n",
        "    model.training_accuracy_ = acc\n",
        "    return model\n",
        "  except Exception as e:\n",
        "    print(f\"Error while training the model: {e}\")\n",
        "    return None\n",
        "\n",
        "baseline_random_seed = 42\n",
        "baseline_model = split_and_train_model(\n",
        "  X,\n",
        "  y,\n",
        "  random_seed=baseline_random_seed,\n",
        "  model_function=LogisticRegression,\n",
        ")\n",
        "\n",
        "baseline_accuracy = None\n",
        "if baseline_model is not None and hasattr(baseline_model, \"training_accuracy_\"):\n",
        "  baseline_accuracy = baseline_model.training_accuracy_\n",
        "  print(f\"Baseline Logistic Regression accuracy: {baseline_accuracy:.4f}\")\n",
        "else:\n",
        "  print(\"Baseline model was not trained successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg7sLMD8o5wS"
      },
      "outputs": [],
      "source": [
        "# no asserts there!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jslHSd-Mhnk8"
      },
      "source": [
        "# ðŸ§© Task 4 (2 points): Feature extraction - clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I42INxTThxf4"
      },
      "source": [
        "Someone from SNAILAB theorized that knowing the genus of the plant which the leaf belongs to should help predict the genus of the snail, as certain snails are attracted to certain plants. However, the dataset does not contain plant names, and either way, plant identification requires additional time and skill.\n",
        "\n",
        "Instead, you can use unsupervised learning to cluster plant features and use this information as a new feature.\n",
        "\n",
        "1. (0.1p) Create a new DataFrame `plants` containing only plant features from `transformed`. Here, you are allowed to write column names manually.\n",
        "2. (0.9p) You will use several clustering methods: [Affinity Propagation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html), [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html), [Spectral Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html), and [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans). They allow to provide different clustering parameters. Create a list `cluster_setups` containing `tuple[str, Callable, dict]` items (setups), where `str` is a short model name just for printing purposes, `Callable` is the clustering function (which you will call), and `dict` is a dictionary of 1-2 parameters to provide to that function.\n",
        "   - There should be several setups for each clustering method. Use `for` loops to create those setups automatically by going through lists of possible parameters. You are allowed to write the lists manually or use `np.linspace` and similar functions:\n",
        "      - For Affinity Propagation, use 2-3 different `damping` values between 0.6 and 0.9;\n",
        "      - For Spectral Clustering and KMeans, use 4-5 `n_clusters` values between 3 and 20.\n",
        "      - For DBSCAN, use 4-5 `eps` values between 0.1 and 0.5, and 4-5 `min_samples` values between 5 and 40 (so each DBSCAN setup had two provided parameters instead of one).\n",
        "3. (1.0p) For each setup in `cluster_setups`, fit a clustering model on `plants` data and get the preidcted labels for all plants. Save the labels into a dictionary `obtained_clusters` which should be of type `dict[str, list]`, The `str` keys should be some kind of automatically generated short model descriptions (e.g. use f-string and include used parameter values in it). The `list` values should be lists of predicted cluster labels.\n",
        "   - You may want to use `tqdm` at this point, as some clustering methods are slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7fvuZXGhy1R"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "#dataframe\n",
        "plant_like_substrings = [\"plant\", \"leaf\"]\n",
        "\n",
        "candidate_cols = [\n",
        "  col\n",
        "  for col in X.columns\n",
        "  if any(sub in col.lower() for sub in plant_like_substrings)\n",
        "]\n",
        "\n",
        "if len(candidate_cols) == 0:\n",
        "  print(\"Could not automatically find plant-specific columns; using all feature columns instead.\")\n",
        "  candidate_cols = list(X.columns)\n",
        "\n",
        "plants = X[candidate_cols].copy()\n",
        "print(f\"Number of plant feature columns used: {len(plants.columns)}\")\n",
        "\n",
        "#2\n",
        "cluster_setups = []\n",
        "\n",
        "#Affinity Propagation\n",
        "for damping in [0.6, 0.7, 0.8]:\n",
        "  params = {\"damping\": damping}\n",
        "  cluster_setups.append((\"AffinityPropagation\", AffinityPropagation, params))\n",
        "\n",
        "#Spectral Clustering\n",
        "for n_clusters in [3, 5, 8, 12, 16]:\n",
        "  params = {\n",
        "    \"n_clusters\": n_clusters,\n",
        "    \"assign_labels\": \"kmeans\",\n",
        "    \"random_state\": 42,\n",
        "  }\n",
        "  cluster_setups.append((\"SpectralClustering\", SpectralClustering, params))\n",
        "\n",
        "#KMeans\n",
        "for n_clusters in [3, 5, 8, 12, 16]:\n",
        "  params = {\n",
        "    \"n_clusters\": n_clusters,\n",
        "    \"n_init\": 10,\n",
        "    \"random_state\": 42,\n",
        "  }\n",
        "  cluster_setups.append((\"KMeans\", KMeans, params))\n",
        "\n",
        "#DBSCAN\n",
        "eps_values = np.linspace(0.1, 0.5, 5)\n",
        "min_samples_values = [4, 5, 7, 11, 20]\n",
        "\n",
        "for eps in eps_values:\n",
        "  for min_samples in min_samples_values:\n",
        "    params = {\n",
        "      \"eps\": float(eps),\n",
        "      \"min_samples\": min_samples,\n",
        "    }\n",
        "    cluster_setups.append((\"DBSCAN\", DBSCAN, params))\n",
        "\n",
        "print(f\"Total clustering setups prepared: {len(cluster_setups)}\")\n",
        "\n",
        "obtained_clusters = {}\n",
        "\n",
        "#3\n",
        "for method_name, model_cls, params in tqdm(cluster_setups):\n",
        "  model = model_cls(**params)\n",
        "  try:\n",
        "    labels = model.fit_predict(plants)\n",
        "  except Exception as e:\n",
        "    print(f\"Clustering failed for {method_name} with params {params}: {e}\")\n",
        "    labels = np.zeros(len(plants), dtype=int)\n",
        "  feature_name = method_name + \"_\" + \"_\".join(f\"{k}={v}\" for k, v in params.items())\n",
        "  obtained_clusters[feature_name] = list(labels)\n",
        "\n",
        "print(f\"Successfully obtained {len(obtained_clusters)} clustering feature sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTzjEaMoqz3H"
      },
      "outputs": [],
      "source": [
        "assert isinstance(plants, pd.DataFrame)\n",
        "assert isinstance(cluster_setups, list)\n",
        "assert isinstance(obtained_clusters, dict)\n",
        "assert len(cluster_setups) == len(obtained_clusters)\n",
        "assert len(cluster_setups) >= 26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uKxDGaZxb0D"
      },
      "source": [
        "# ðŸ‘‘ Task 5 (2 points): Using extracted features to improve the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuAg6E1bqzuC"
      },
      "source": [
        "The only thing left now is to check which clustering setup produced a new feature (predicted plant clusters) which improves the Logistic Regression model trained in Task 3.\n",
        "\n",
        "1. (1.0p) For each plant clustering result from Task 4, check if it improves the accuracy of logistic regression:\n",
        "   - Create a new variable `XX` containing the `X` from Task 2 but joined with the new feature. If the shape of `X` was (M, N), then the shape of `XX` should be (M, N+1).\n",
        "   - Using already written `split_and_train_model` function, create and fit a new logistic regression model on `XX` (`y` remains unchanged from Task 2). You may need to increase `max_iter` here. Don't forget to use the same random seed for all models.\n",
        "2. (1.0p) Automatically find the feature which produced the best result from all trained Logistic Regression models. Print out its name and received accuracy score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhJD1ZihyCob"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "cluster_model_results = {}\n",
        "cluster_accuracies = {}\n",
        "\n",
        "for feature_name, labels in obtained_clusters.items():\n",
        "  XX = X.copy()\n",
        "  XX[feature_name] = labels\n",
        "\n",
        "  model = split_and_train_model(\n",
        "    XX,\n",
        "    y,\n",
        "    random_seed=baseline_random_seed,\n",
        "    model_function=LogisticRegression,\n",
        "    max_iter=1000\n",
        "  )\n",
        "\n",
        "  if model is not None and hasattr(model, \"training_accuracy_\"):\n",
        "    acc = model.training_accuracy_\n",
        "    cluster_model_results[feature_name] = model\n",
        "    cluster_accuracies[feature_name] = acc\n",
        "    print(f\"Logistic Regression with feature '{feature_name}' accuracy: {acc:.4f}\")\n",
        "  else:\n",
        "    print(f\"Model training failed for feature '{feature_name}'.\")\n",
        "\n",
        "best_feature_name = None\n",
        "best_accuracy = None\n",
        "\n",
        "for fname, acc in cluster_accuracies.items():\n",
        "  if best_accuracy is None or acc > best_accuracy:\n",
        "    best_accuracy = acc\n",
        "    best_feature_name = fname\n",
        "\n",
        "if best_feature_name is not None:\n",
        "  print()\n",
        "  print(f\"Best clustering-based feature: {best_feature_name}\")\n",
        "  print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
        "  if baseline_accuracy is not None:\n",
        "    diff = best_accuracy - baseline_accuracy\n",
        "    print(f\"Improvement over baseline: {diff:+.4f}\")\n",
        "else:\n",
        "  print(\"Could not determine the best feature â€“ no successful models were trained.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTPjKei9yD3c"
      },
      "outputs": [],
      "source": [
        "# no asserts again!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}